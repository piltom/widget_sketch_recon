{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finalMachineLearning-AlvarezVanoli.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNEDXoKB8qeAXY7XJwHu0Sn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piltom/widget_sketch_recon/blob/main/report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDtznQKmlInD"
      },
      "source": [
        "# Reconocimiento de widgets a mano alzada para generar UIs a partir de un borrador\n",
        "## Big Picture\n",
        "Este trabajo es una parte de un proyecto más grande, en el cual se intenta generar una descripción de una interfaz de usuario a partir de una foto de un sketch en papel/pizarra. Con esta descripción se puede después generar código para algún lenguaje/framwork en particular (ReactJS, Qt, Gtk, etc.)\n",
        "Un ejemplo de un par de sketch e interfaz es el siguiente:\n",
        "\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/ideal_example/sketch1.jpg)\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/ideal_example/final_result1.jpg)\n",
        "\n",
        "\n",
        "##Este trabajo\n",
        "En este trabajo, se asume que la imagen original ya fue segmentada en elementos únicos, los cuales deben ser clasificados en categorías. Los elementos posibles por el momento son:\n",
        "\n",
        "###Checkbox:\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/checkbox.png)\n",
        "###Input\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/input.png)\n",
        "\n",
        "###Pushbutton:\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/pushbutton.png)\n",
        "\n",
        "###Radiobutton:\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/radio1.png)\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/radio2.png)\n",
        "\n",
        "###Round Image:\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/roundimg.png)\n",
        "\n",
        "###Square Image:\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/squareimg.png)\n",
        "\n",
        "###Slider:\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/slider.png)\n",
        "\n",
        "###Switch:\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/switch1.png)\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/switch2.png)\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/switch3.png)\n",
        "\n",
        "###Text:\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/text1.png)\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/sample_elements/text2.png)\n",
        "\n",
        "#Generación del dataset\n",
        "El dataset fue dibujado sobre hojas cuadriculadas con lapicera azul, en formato de \"sprite sheet\" (rectángulos de un mismo tamaño contiguos). El fondo cuadriculado seguramente sea el \"peor caso\" de ruido de fondo posible, ya que alternativamente podría ser una hoja rayada o una pizarra. Se dibujaron diversas variaciones de cada elemento, utilizando distintos trazos (continuos, lineas, figuras que no llegan a cerrar, partes pintadas, etc.). En [MEGA](https://mega.nz/file/IUhz3KoB#ZqoRcKabLWs6Y8_xd8Rqv8WJIc1NzcchaOsEAV8c6n0) se encuentran tanto los \"sprite sheets\" como cada \"tile\" separado.\n",
        "\n",
        "#Procesamiento y extracción de features\n",
        "##Preprocesamiento\n",
        "Antes de poder extraer features de las imágenes, se debe ajustar el tamaño de las imágenes y filtrar el fondo cuadriculado. Para esto se utiliza el script [adecuate.py](https://github.com/piltom/widget_sketch_recon/blob/main/util_test_scripts/adecuate.py), que cambia el tamaño de las imágenes para que tengan 256 pixeles de ancho y aplica un [threshold Li](https://scikit-image.org/docs/dev/auto_examples/developers/plot_threshold_li.html) para filtrar el fondo.\n",
        "\n",
        "Un ejemplo del resultado de esta adecuación es:\n",
        "\n",
        "![](https://raw.githubusercontent.com/piltom/widget_sketch_recon/main/img/pushbutton/tile008_p.png)\n",
        "\n",
        "**Nota: Posiblemente se podría reducir el tamaño de las imágenes aún más, cortando las partes negras en los bordes.**\n",
        "\n",
        "##Features\n",
        "Para este trabajo se consideraron tres métodos de extracción de features diferentes, con los cuales se generaron diversos dataframes alterando parámetros y se analizó la efectividad de los mismos usando un Support Vector Classifier y un Random Forest Classifier. Para generar los dataframes se utilizaron los scripts [create_widget_dataset.py](https://github.com/piltom/widget_sketch_recon/blob/main/create_widget_dataset.py) (ORB), [create_widget_dataset_hough.py](https://github.com/piltom/widget_sketch_recon/blob/main/create_widget_dataset_hough.py) (Transformada de Hough), [create_widget_dataset_houghncross.py](https://github.com/piltom/widget_sketch_recon/blob/main/create_widget_dataset_houghncross.py) (Transformada de Hough y cruce de lineas en centroide)\n",
        "###ORB\n",
        "Oriented FAST and Rotated Brief es un detector de features locales robusto que se utiliza frecuentemente en tareas de reconocimiento de objetos y reconstrucción 3D. Es robusto frente a rotaciones y cambios de escala, por lo que es muy útil cuando se tratan objetos 3D tomados desde distintos ángulos.\n",
        "\n",
        "Para este caso se crearon dos datasets, uno con 50 keypoints y otro con 200. El resultado obtenido se muestra a continuación, seguido de una explicación de su falla para este caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM3Gval1lHX3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}